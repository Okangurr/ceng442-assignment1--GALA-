{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a713c9bd",
   "metadata": {},
   "source": [
    "# Ödev Açıklaması:\n",
    "- 5 Farklı Azerbaycanca dataseti Sentiment Analizi için temizleyeceğiz.\n",
    "\n",
    "- Etiketler(labels) üç kutuplu ve sayısal olacak. => Negative=0.0, Neutral =0.5 Positive = 1.0\n",
    "\n",
    "- Her dataset için 2 sütunlu Excel(xslx) üret: text,label featureları olucak\n",
    "\n",
    "- Temizlediğimiz metinlerle Word2Vec ve FastText(gensim) modellerini eğit\n",
    "\n",
    "- Pipeline hafif düzeyde alan(domain) farkındalığı içersin.(news,social,reviews,general)\n",
    "\n",
    "- Kurulum ve tekrar çalıştırma kolay ve tekrarlanabilir olsun(seed,requirements,README)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78c3eb",
   "metadata": {},
   "source": [
    "# Teslim Edilmesi Gerekenler\n",
    "1. Temizlenmiş data dosyaları:\n",
    "    5 adet .xlsx(her biri 2 sütun feature olan text-label),UTF-8 uyumlu olmalı\n",
    "2. Kodlar:\n",
    "    - preprocess.py(temizleme + etiketleri sayıya çevirme + xlsx yazma)\n",
    "    - train_embeddings.py(Word2Vec ve FastText eğitimi ve kaydetme)\n",
    "3. Modeller:\n",
    "    - models/word2vec_<domain>.model\n",
    "    - models/fasttext_<domain>.model veya .bin\n",
    "4. README.md:\n",
    "    Adım adım çalıştırma,Python/kitaplık sürümleri,seed,ortalama eğitim süresi ve örnek komutlar\n",
    "5. requirements.txt:\n",
    "    - pandas, gensim, openpyxl, vb. sürümleri sabitle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8575a8",
   "metadata": {},
   "source": [
    "# Yapmamız gerekenler:\n",
    "1. 5 veri kümesini temizle -> 5 excel dosyası üret\n",
    "2. Bu Excel dosyalarındaki metinleri birleştir -> corpus_all.txt oluştur\n",
    "3. Bu birleştirdiğimiz metinle (corpus_all.txt) ile iki modeli eğit: word2vec.model ve fasttext.model\n",
    "4. Tümünü Githuba yükleyeceğiz:\n",
    "    - data_clean/*.xlsx\n",
    "    - corpus_all.txt\n",
    "    - embeddings/word2vec.model\n",
    "    - embeddings/fasttext.model\n",
    "    - README.md (kısa rapor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e016923",
   "metadata": {},
   "source": [
    "# Şimdi yapmaya başlayalım İlk yapacağımız iş Data Cleaning Verileri temizleyelim.\n",
    "1. Excel labeled-sentiment.xlsx \n",
    "    Features: text,sentiment(3 tane sınıf var metinle girilmiş negative/neutral/positive) şekilde \n",
    "2. test__1_.xslx \n",
    "    Features text,label(label'lar genelde 0 ve 1 olarak verilmiş) 0=>negative 1 =>positive\n",
    "3. train__3_xslx\n",
    "    Features text,label(0 ve 1)\n",
    "4. train-00000-of-00001.xlsx\n",
    "    Features text,labels bu da metin olarak (positive/negative/neutral) olarak verilmiş\n",
    "5. merged_dataset_CSV__1_xlsx\n",
    "    Features text,labels(0,1)\n",
    "    Bu datasette dikkat etmemiz gereken şey bazı excellerde otomatik eklenen Unnamed:* gibi bir index sütunu var Bunu almayacağız buna göre ele alacağız.\n",
    "\n",
    "Label'lar için \n",
    "- negative/neg/-1/0 -> 0.0 yapacağız\n",
    "- neutral/neu/0.5/ 1/2 / -> 0.5 yapacağız\n",
    "- positive/pos/1/p -> 1.0 yapacağız\n",
    "- Binary setlerde(neutral yok):Negatif örnekler 0.0 a pozitifler 1.0'a gider \n",
    "\n",
    "\n",
    "Excellerin herbirini ayrı ayrı şekilde temizleyeceğiz daha sonra da her birini data_clean/<dataadı>.xlsx şeklinde kaydedeceğiz.Excel sütunları cleaned_text ve sentiment_value şeklinde olacak.\n",
    "\n",
    "Temiz Exceller hazır olunca bu 5 temiz Excel'i tek metin dosyasında toplayacağız: \n",
    "    Her satır: dom<domain> <cleaned sentence>\n",
    "                Örnek:domnews sabah bakida yagis var \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096d7fb",
   "metadata": {},
   "source": [
    "# Hangi Teknolojileri kullanacağız ve Neden?\n",
    "1. Python 3 -> Tüm scriptleri çalıştıracağımız ortam.\n",
    "2. pandas -> Excel okuma/yazma, vektörize temizlik(hızlı str.replace,map vb.)\n",
    "3. regex (re) -> URL,e-posta,@mention,#hashtag,sayılar gibi kalıpları yakalayıp temizlemek için \n",
    "4. unicodedata -> Azerbaycanca'ya duyarlı harf dönüşümü ve Unicode normalizasyonu(örn. farklı “İ/ı” varyantları, birleşik karakterler)\n",
    "5. ftfy (opsiyonel) → Kırık/bozuk metin kodlamalarını düzeltmek için pratik (smart quotes, mojibake).\n",
    "6. gensim → Word2Vec ve FastText eğitimleri.\n",
    "7. openpyxl → pandas’ın .xlsx I/O motoru (Excel’le konuşan kütüphane).\n",
    "8. scikit-learn (opsiyonel) → Sınıflandırma yapmayacağız ama istersen küçük sanity-check’ler, train/test ayırma, karıştırma vs. için işe yarar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639d831",
   "metadata": {},
   "source": [
    "# Basit Temizlik Kuralları(Azericeye özel şeyler var burada)\n",
    "1. Lowercase with Azerbaijani rules:\n",
    "    replace İ->i , I->ı before lower() \n",
    "    Normal lower() fonksiyonu Türkçe ve Azerice de hatalı çalışır.Çünkü İ harfini i yerine ı yapar.\n",
    "    Önce dönüşüm yapmamız gerek daha sonra lower yapmamız gerek.\n",
    "    def az_lower(s):\n",
    "    return s.replace(\"İ\", \"i\").replace(\"I\", \"ı\").lower()\n",
    "\n",
    "2. REGEX'leri placeholderlar ile değiştir (URL's,emails,phone numbers, mentions):\n",
    "    “URLs→URL, emails→EMAIL, phone numbers→PHONE, @mentions→USER”\n",
    "    Yani metinde geçen özel yapıları yer tutucularla(placeholder) değiştir.\n",
    "    Örnek: Bu gün www.news.az saytında gördüm → Bu gün URL saytında gördüm  \n",
    "           Əlaqə:  test@mail.az → Əlaqə: EMAIL  \n",
    "           Zəng et: 050-123-45-67 → Zəng et: PHONE  \n",
    "           @aygun yazdı → USER yazdı\n",
    "\n",
    "3. Strip HTML tags/entities;drop but keep hastag text:\n",
    "     \"#\" işaretini kaldır ama hastag içeriğini koru, camelCase hastagleri böl (örn:#BakuCityLife -> baku city life)\n",
    "\n",
    "4. Collapse ≥3 repeated letters to 2\n",
    "    Üç veya daha fazla aynı harf arka arkaya gelirse ikiye indir.\n",
    "    Böylece abartılı yazımın etkisi korunur ama gürültü azalır.\n",
    "    coooool -> coool \n",
    "\n",
    "5. Replace digits with <NUM>\n",
    "    Sayıları \"<NUM>\" etiketi ile değiştir.\n",
    "\n",
    "6. Remove standalone punctuation and extra spaces\n",
    "    Yalnız noktalama işaretleriyle oluşan tokenleri kaldır.\n",
    "    Fazla boşlukları teke indir.\n",
    "    Şu harfleri korumamız gerek: ə, ğ, ı, ö, ü, ç, ş (ve x, q)\n",
    "\n",
    "7. Remove single-letter tokens except o, e\n",
    "    Yani “a”, “u”, “t” gibi tek harfli kelimeleri kaldır ama “o” ve “e” kalsın.\n",
    "    o mənim → o mənim  \n",
    "    a çox yaxşı → çox yaxşı\n",
    "\n",
    "8. Drop exact duplicates and empty rows\n",
    "    Aynı metin satırı birden fazla varsa tekini tut,boş satır varsa kaldır.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c09adf",
   "metadata": {},
   "source": [
    "# Mini Challenges Kısmı\n",
    "1. Hastag Split(örnek:#QarabagIsBack → qarabag is back)\n",
    "    Amaç: camelCase/TitleCase hashtag’i kelimelere bölmek, # işaretini atmak.\n",
    "    Bu kısmı clean_text yapmadan önce lowercase yapmandan önce çağırmak iyi olur; sonra az-lover ile küçültme yaparız\n",
    "\n",
    "2. Emoji mapping (tokenization’dan önce küçük eşleme)\n",
    "    Amaç: Emojileri EMO_POS /EMO_NEG gibi sabitlere çevirmek \n",
    "    EMOJI_MAP = {\n",
    "    \"😀\":\"EMO_POS\",\"😃\":\"EMO_POS\",\"😄\":\"EMO_POS\",\"😁\":\"EMO_POS\",\"😊\":\"EMO_POS\",\"🙂\":\"EMO_POS\",\"😍\":\"EMO_POS\",\"👍\":\"EMO_POS\",\"❤️\":\"EMO_POS\",\"🥳\":\"EMO_POS\",\n",
    "    \"😞\":\"EMO_NEG\",\"😠\":\"EMO_NEG\",\"😡\":\"EMO_NEG\",\"😢\":\"EMO_NEG\",\"😭\":\"EMO_NEG\",\"👎\":\"EMO_NEG\",\"☹️\":\"EMO_NEG\",\"🤬\":\"EMO_NEG\"\n",
    "    }\n",
    "    def map_emojis(s: str) -> str:\n",
    "        return ''.join(EMOJI_MAP.get(ch, ch) for ch in s)\n",
    "\n",
    "3. Stopword Araştırması(Azeri+başka bir dil)\n",
    "    İstek: Azerice stopword’leri başka bir dille (TR/EN/RU) karşılaştır; 10 aday öner (negasyonları atma!).\n",
    "\n",
    "        Atılmaması gereken negasyonlar: yox, deyil, heç, qətiyyən, yoxdur (model için önemli sinyal).\n",
    "\n",
    "        Önerilen 10 aday (domaine göre güncellenebilir):\n",
    "\n",
    "            1. və (ve), 2. amma (ama), 3. ki, 4. bu, 5. həm,\n",
    "\n",
    "            2.hər, 7. bütün, 8. ilə (ile), 9. kimi, 10. belə\n",
    "\n",
    "        Not: “da/de” (Azeri’de da, də) da güçlü aday; ayrıca mı/mi karşılığı parçacıklar (mı/mi yok ama mı, mi benzeri sorma ekleri Azerice’de farklı işler). Küçük bir pilot EDA ile en sık 50 kelimeden domain-spesifik 10 seçebilirsin.\n",
    "\n",
    "4. Negation scope (toggle): negator’dan sonra 3 token işaretle \n",
    "    İstek: Negasyon kelimesi görülürse sonraki 3 token’a _NEG eki ekle.\n",
    "    \n",
    "    Örnek:“yox xoşuma gəldi” → “yox xoşuma_NEG gəldi_NEG …”\n",
    "\n",
    "    Değerlendirme fikri: Bu işaretleme açık/kapalıyken Word2Vec’te “xoşuma_NEG” gibi tokenlerin en yakın komşuları nasıl değişiyor? Küçük örnek tabloyla nitel kıyas yap.\n",
    "\n",
    "5. Simple deasciify (ör.: cox→çox, yaxsi→yaxşı)\n",
    "    Amaç:ASCII yazılmış Azeri karakterlerini basit haritayla düzeltmek.\n",
    "    “Raporda kaç token değişti?” sorusu için changed sayısını yaz.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
