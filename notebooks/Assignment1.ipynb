{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a713c9bd",
   "metadata": {},
   "source": [
    "# Ã–dev AÃ§Ä±klamasÄ±:\n",
    "- 5 FarklÄ± Azerbaycanca dataseti Sentiment Analizi iÃ§in temizleyeceÄŸiz.\n",
    "\n",
    "- Etiketler(labels) Ã¼Ã§ kutuplu ve sayÄ±sal olacak. => Negative=0.0, Neutral =0.5 Positive = 1.0\n",
    "\n",
    "- Her dataset iÃ§in 2 sÃ¼tunlu Excel(xslx) Ã¼ret: text,label featurelarÄ± olucak\n",
    "\n",
    "- TemizlediÄŸimiz metinlerle Word2Vec ve FastText(gensim) modellerini eÄŸit\n",
    "\n",
    "- Pipeline hafif dÃ¼zeyde alan(domain) farkÄ±ndalÄ±ÄŸÄ± iÃ§ersin.(news,social,reviews,general)\n",
    "\n",
    "- Kurulum ve tekrar Ã§alÄ±ÅŸtÄ±rma kolay ve tekrarlanabilir olsun(seed,requirements,README)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78c3eb",
   "metadata": {},
   "source": [
    "# Teslim Edilmesi Gerekenler\n",
    "1. TemizlenmiÅŸ data dosyalarÄ±:\n",
    "    5 adet .xlsx(her biri 2 sÃ¼tun feature olan text-label),UTF-8 uyumlu olmalÄ±\n",
    "2. Kodlar:\n",
    "    - preprocess.py(temizleme + etiketleri sayÄ±ya Ã§evirme + xlsx yazma)\n",
    "    - train_embeddings.py(Word2Vec ve FastText eÄŸitimi ve kaydetme)\n",
    "3. Modeller:\n",
    "    - models/word2vec_<domain>.model\n",
    "    - models/fasttext_<domain>.model veya .bin\n",
    "4. README.md:\n",
    "    AdÄ±m adÄ±m Ã§alÄ±ÅŸtÄ±rma,Python/kitaplÄ±k sÃ¼rÃ¼mleri,seed,ortalama eÄŸitim sÃ¼resi ve Ã¶rnek komutlar\n",
    "5. requirements.txt:\n",
    "    - pandas, gensim, openpyxl, vb. sÃ¼rÃ¼mleri sabitle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8575a8",
   "metadata": {},
   "source": [
    "# YapmamÄ±z gerekenler:\n",
    "1. 5 veri kÃ¼mesini temizle -> 5 excel dosyasÄ± Ã¼ret\n",
    "2. Bu Excel dosyalarÄ±ndaki metinleri birleÅŸtir -> corpus_all.txt oluÅŸtur\n",
    "3. Bu birleÅŸtirdiÄŸimiz metinle (corpus_all.txt) ile iki modeli eÄŸit: word2vec.model ve fasttext.model\n",
    "4. TÃ¼mÃ¼nÃ¼ Githuba yÃ¼kleyeceÄŸiz:\n",
    "    - data_clean/*.xlsx\n",
    "    - corpus_all.txt\n",
    "    - embeddings/word2vec.model\n",
    "    - embeddings/fasttext.model\n",
    "    - README.md (kÄ±sa rapor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e016923",
   "metadata": {},
   "source": [
    "# Åimdi yapmaya baÅŸlayalÄ±m Ä°lk yapacaÄŸÄ±mÄ±z iÅŸ Data Cleaning Verileri temizleyelim.\n",
    "1. Excel labeled-sentiment.xlsx \n",
    "    Features: text,sentiment(3 tane sÄ±nÄ±f var metinle girilmiÅŸ negative/neutral/positive) ÅŸekilde \n",
    "2. test__1_.xslx \n",
    "    Features text,label(label'lar genelde 0 ve 1 olarak verilmiÅŸ) 0=>negative 1 =>positive\n",
    "3. train__3_xslx\n",
    "    Features text,label(0 ve 1)\n",
    "4. train-00000-of-00001.xlsx\n",
    "    Features text,labels bu da metin olarak (positive/negative/neutral) olarak verilmiÅŸ\n",
    "5. merged_dataset_CSV__1_xlsx\n",
    "    Features text,labels(0,1)\n",
    "    Bu datasette dikkat etmemiz gereken ÅŸey bazÄ± excellerde otomatik eklenen Unnamed:* gibi bir index sÃ¼tunu var Bunu almayacaÄŸÄ±z buna gÃ¶re ele alacaÄŸÄ±z.\n",
    "\n",
    "Label'lar iÃ§in \n",
    "- negative/neg/-1/0 -> 0.0 yapacaÄŸÄ±z\n",
    "- neutral/neu/0.5/ 1/2 / -> 0.5 yapacaÄŸÄ±z\n",
    "- positive/pos/1/p -> 1.0 yapacaÄŸÄ±z\n",
    "- Binary setlerde(neutral yok):Negatif Ã¶rnekler 0.0 a pozitifler 1.0'a gider \n",
    "\n",
    "\n",
    "Excellerin herbirini ayrÄ± ayrÄ± ÅŸekilde temizleyeceÄŸiz daha sonra da her birini data_clean/<dataadÄ±>.xlsx ÅŸeklinde kaydedeceÄŸiz.Excel sÃ¼tunlarÄ± cleaned_text ve sentiment_value ÅŸeklinde olacak.\n",
    "\n",
    "Temiz Exceller hazÄ±r olunca bu 5 temiz Excel'i tek metin dosyasÄ±nda toplayacaÄŸÄ±z: \n",
    "    Her satÄ±r: dom<domain> <cleaned sentence>\n",
    "                Ã–rnek:domnews sabah bakida yagis var \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096d7fb",
   "metadata": {},
   "source": [
    "# Hangi Teknolojileri kullanacaÄŸÄ±z ve Neden?\n",
    "1. Python 3 -> TÃ¼m scriptleri Ã§alÄ±ÅŸtÄ±racaÄŸÄ±mÄ±z ortam.\n",
    "2. pandas -> Excel okuma/yazma, vektÃ¶rize temizlik(hÄ±zlÄ± str.replace,map vb.)\n",
    "3. regex (re) -> URL,e-posta,@mention,#hashtag,sayÄ±lar gibi kalÄ±plarÄ± yakalayÄ±p temizlemek iÃ§in \n",
    "4. unicodedata -> Azerbaycanca'ya duyarlÄ± harf dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve Unicode normalizasyonu(Ã¶rn. farklÄ± â€œÄ°/Ä±â€ varyantlarÄ±, birleÅŸik karakterler)\n",
    "5. ftfy (opsiyonel) â†’ KÄ±rÄ±k/bozuk metin kodlamalarÄ±nÄ± dÃ¼zeltmek iÃ§in pratik (smart quotes, mojibake).\n",
    "6. gensim â†’ Word2Vec ve FastText eÄŸitimleri.\n",
    "7. openpyxl â†’ pandasâ€™Ä±n .xlsx I/O motoru (Excelâ€™le konuÅŸan kÃ¼tÃ¼phane).\n",
    "8. scikit-learn (opsiyonel) â†’ SÄ±nÄ±flandÄ±rma yapmayacaÄŸÄ±z ama istersen kÃ¼Ã§Ã¼k sanity-checkâ€™ler, train/test ayÄ±rma, karÄ±ÅŸtÄ±rma vs. iÃ§in iÅŸe yarar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639d831",
   "metadata": {},
   "source": [
    "# Basit Temizlik KurallarÄ±(Azericeye Ã¶zel ÅŸeyler var burada)\n",
    "1. Lowercase with Azerbaijani rules:\n",
    "    replace Ä°->i , I->Ä± before lower() \n",
    "    Normal lower() fonksiyonu TÃ¼rkÃ§e ve Azerice de hatalÄ± Ã§alÄ±ÅŸÄ±r.Ã‡Ã¼nkÃ¼ Ä° harfini i yerine Ä± yapar.\n",
    "    Ã–nce dÃ¶nÃ¼ÅŸÃ¼m yapmamÄ±z gerek daha sonra lower yapmamÄ±z gerek.\n",
    "    def az_lower(s):\n",
    "    return s.replace(\"Ä°\", \"i\").replace(\"I\", \"Ä±\").lower()\n",
    "\n",
    "2. REGEX'leri placeholderlar ile deÄŸiÅŸtir (URL's,emails,phone numbers, mentions):\n",
    "    â€œURLsâ†’URL, emailsâ†’EMAIL, phone numbersâ†’PHONE, @mentionsâ†’USERâ€\n",
    "    Yani metinde geÃ§en Ã¶zel yapÄ±larÄ± yer tutucularla(placeholder) deÄŸiÅŸtir.\n",
    "    Ã–rnek: Bu gÃ¼n www.news.az saytÄ±nda gÃ¶rdÃ¼m â†’ Bu gÃ¼n URL saytÄ±nda gÃ¶rdÃ¼m  \n",
    "           ÆlaqÉ™:  test@mail.az â†’ ÆlaqÉ™: EMAIL  \n",
    "           ZÉ™ng et: 050-123-45-67 â†’ ZÉ™ng et: PHONE  \n",
    "           @aygun yazdÄ± â†’ USER yazdÄ±\n",
    "\n",
    "3. Strip HTML tags/entities;drop but keep hastag text:\n",
    "     \"#\" iÅŸaretini kaldÄ±r ama hastag iÃ§eriÄŸini koru, camelCase hastagleri bÃ¶l (Ã¶rn:#BakuCityLife -> baku city life)\n",
    "\n",
    "4. Collapse â‰¥3 repeated letters to 2\n",
    "    ÃœÃ§ veya daha fazla aynÄ± harf arka arkaya gelirse ikiye indir.\n",
    "    BÃ¶ylece abartÄ±lÄ± yazÄ±mÄ±n etkisi korunur ama gÃ¼rÃ¼ltÃ¼ azalÄ±r.\n",
    "    coooool -> coool \n",
    "\n",
    "5. Replace digits with <NUM>\n",
    "    SayÄ±larÄ± \"<NUM>\" etiketi ile deÄŸiÅŸtir.\n",
    "\n",
    "6. Remove standalone punctuation and extra spaces\n",
    "    YalnÄ±z noktalama iÅŸaretleriyle oluÅŸan tokenleri kaldÄ±r.\n",
    "    Fazla boÅŸluklarÄ± teke indir.\n",
    "    Åu harfleri korumamÄ±z gerek: É™, ÄŸ, Ä±, Ã¶, Ã¼, Ã§, ÅŸ (ve x, q)\n",
    "\n",
    "7. Remove single-letter tokens except o, e\n",
    "    Yani â€œaâ€, â€œuâ€, â€œtâ€ gibi tek harfli kelimeleri kaldÄ±r ama â€œoâ€ ve â€œeâ€ kalsÄ±n.\n",
    "    o mÉ™nim â†’ o mÉ™nim  \n",
    "    a Ã§ox yaxÅŸÄ± â†’ Ã§ox yaxÅŸÄ±\n",
    "\n",
    "8. Drop exact duplicates and empty rows\n",
    "    AynÄ± metin satÄ±rÄ± birden fazla varsa tekini tut,boÅŸ satÄ±r varsa kaldÄ±r.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c09adf",
   "metadata": {},
   "source": [
    "# Mini Challenges KÄ±smÄ±\n",
    "1. Hastag Split(Ã¶rnek:#QarabagIsBack â†’ qarabag is back)\n",
    "    AmaÃ§: camelCase/TitleCase hashtagâ€™i kelimelere bÃ¶lmek, # iÅŸaretini atmak.\n",
    "    Bu kÄ±smÄ± clean_text yapmadan Ã¶nce lowercase yapmandan Ã¶nce Ã§aÄŸÄ±rmak iyi olur; sonra az-lover ile kÃ¼Ã§Ã¼ltme yaparÄ±z\n",
    "\n",
    "2. Emoji mapping (tokenizationâ€™dan Ã¶nce kÃ¼Ã§Ã¼k eÅŸleme)\n",
    "    AmaÃ§: Emojileri EMO_POS /EMO_NEG gibi sabitlere Ã§evirmek \n",
    "    EMOJI_MAP = {\n",
    "    \"ğŸ˜€\":\"EMO_POS\",\"ğŸ˜ƒ\":\"EMO_POS\",\"ğŸ˜„\":\"EMO_POS\",\"ğŸ˜\":\"EMO_POS\",\"ğŸ˜Š\":\"EMO_POS\",\"ğŸ™‚\":\"EMO_POS\",\"ğŸ˜\":\"EMO_POS\",\"ğŸ‘\":\"EMO_POS\",\"â¤ï¸\":\"EMO_POS\",\"ğŸ¥³\":\"EMO_POS\",\n",
    "    \"ğŸ˜\":\"EMO_NEG\",\"ğŸ˜ \":\"EMO_NEG\",\"ğŸ˜¡\":\"EMO_NEG\",\"ğŸ˜¢\":\"EMO_NEG\",\"ğŸ˜­\":\"EMO_NEG\",\"ğŸ‘\":\"EMO_NEG\",\"â˜¹ï¸\":\"EMO_NEG\",\"ğŸ¤¬\":\"EMO_NEG\"\n",
    "    }\n",
    "    def map_emojis(s: str) -> str:\n",
    "        return ''.join(EMOJI_MAP.get(ch, ch) for ch in s)\n",
    "\n",
    "3. Stopword AraÅŸtÄ±rmasÄ±(Azeri+baÅŸka bir dil)\n",
    "    Ä°stek: Azerice stopwordâ€™leri baÅŸka bir dille (TR/EN/RU) karÅŸÄ±laÅŸtÄ±r; 10 aday Ã¶ner (negasyonlarÄ± atma!).\n",
    "\n",
    "        AtÄ±lmamasÄ± gereken negasyonlar: yox, deyil, heÃ§, qÉ™tiyyÉ™n, yoxdur (model iÃ§in Ã¶nemli sinyal).\n",
    "\n",
    "        Ã–nerilen 10 aday (domaine gÃ¶re gÃ¼ncellenebilir):\n",
    "\n",
    "            1. vÉ™ (ve), 2. amma (ama), 3. ki, 4. bu, 5. hÉ™m,\n",
    "\n",
    "            2.hÉ™r, 7. bÃ¼tÃ¼n, 8. ilÉ™ (ile), 9. kimi, 10. belÉ™\n",
    "\n",
    "        Not: â€œda/deâ€ (Azeriâ€™de da, dÉ™) da gÃ¼Ã§lÃ¼ aday; ayrÄ±ca mÄ±/mi karÅŸÄ±lÄ±ÄŸÄ± parÃ§acÄ±klar (mÄ±/mi yok ama mÄ±, mi benzeri sorma ekleri Azericeâ€™de farklÄ± iÅŸler). KÃ¼Ã§Ã¼k bir pilot EDA ile en sÄ±k 50 kelimeden domain-spesifik 10 seÃ§ebilirsin.\n",
    "\n",
    "4. Negation scope (toggle): negatorâ€™dan sonra 3 token iÅŸaretle \n",
    "    Ä°stek: Negasyon kelimesi gÃ¶rÃ¼lÃ¼rse sonraki 3 tokenâ€™a _NEG eki ekle.\n",
    "    \n",
    "    Ã–rnek:â€œyox xoÅŸuma gÉ™ldiâ€ â†’ â€œyox xoÅŸuma_NEG gÉ™ldi_NEG â€¦â€\n",
    "\n",
    "    DeÄŸerlendirme fikri: Bu iÅŸaretleme aÃ§Ä±k/kapalÄ±yken Word2Vecâ€™te â€œxoÅŸuma_NEGâ€ gibi tokenlerin en yakÄ±n komÅŸularÄ± nasÄ±l deÄŸiÅŸiyor? KÃ¼Ã§Ã¼k Ã¶rnek tabloyla nitel kÄ±yas yap.\n",
    "\n",
    "5. Simple deasciify (Ã¶r.: coxâ†’Ã§ox, yaxsiâ†’yaxÅŸÄ±)\n",
    "    AmaÃ§:ASCII yazÄ±lmÄ±ÅŸ Azeri karakterlerini basit haritayla dÃ¼zeltmek.\n",
    "    â€œRaporda kaÃ§ token deÄŸiÅŸti?â€ sorusu iÃ§in changed sayÄ±sÄ±nÄ± yaz.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
